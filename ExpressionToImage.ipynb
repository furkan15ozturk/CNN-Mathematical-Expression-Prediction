{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ff986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.contours import sort_contours\n",
    "import imutils\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e95f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_data_dir = \"extracted_images\"\n",
    "data_dir = pathlib.Path(str_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1622894",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_height = 45\n",
    "img_width = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3495ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 186139 files belonging to 16 classes.\n",
      "Using 148912 files for training.\n",
      "Found 186139 files belonging to 16 classes.\n",
      "Using 37227 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = 123,\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a91508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(',\n",
       " ')',\n",
       " '+',\n",
       " '-',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'div',\n",
       " 'times']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448dba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 45, 45, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8bbfef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa760abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b71b9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 16\n",
    "factor = 0.01\n",
    "rate = 0.3\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding=\"same\", kernel_regularizer=l2(factor)),\n",
    "    Dropout(rate),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding=\"same\", kernel_regularizer=l2(factor)),\n",
    "    Dropout(rate),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', padding=\"same\", kernel_regularizer=l2(factor)),\n",
    "    Dropout(rate),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdbae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06e03efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327/2327 [==============================] - 194s 83ms/step - loss: 0.3973 - accuracy: 0.9263 - val_loss: 0.4164 - val_accuracy: 0.9642\n",
      "Epoch 2/3\n",
      "2327/2327 [==============================] - 195s 84ms/step - loss: 0.1924 - accuracy: 0.9671 - val_loss: 0.3132 - val_accuracy: 0.9745\n",
      "Epoch 3/3\n",
      "2327/2327 [==============================] - 197s 85ms/step - loss: 0.1655 - accuracy: 0.9706 - val_loss: 0.2550 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c76e9c7a30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "train_ds,\n",
    "validation_data = val_ds,\n",
    "epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc53e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, 45, 45, 3)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 45, 45, 32)        896       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 45, 45, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 22, 22, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 22, 22, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 11, 11, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 11, 11, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                12816     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,208\n",
      "Trainable params: 32,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e68234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mathematical_expressionv7.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mathematical_expressionv7.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mathematical_expressionv7.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7fd397",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(val_loss,val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7133b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
